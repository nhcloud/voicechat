{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33475b8a",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Architecture Overview\n",
    "\n",
    "The voice chat application uses a **three-tier architecture**:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     WebSocket     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     WebSocket     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   Browser UI    ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ  Backend Server  ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ Azure OpenAI        ‚îÇ\n",
    "‚îÇ  (JavaScript)   ‚îÇ                  ‚îÇ    (Python)      ‚îÇ                  ‚îÇ Realtime API        ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚îÇ                                    ‚îÇ                                      ‚îÇ\n",
    "        ‚îÇ  ‚Ä¢ Captures microphone             ‚îÇ  ‚Ä¢ Proxies messages                  ‚îÇ  ‚Ä¢ Speech-to-Text\n",
    "        ‚îÇ  ‚Ä¢ Plays audio response            ‚îÇ  ‚Ä¢ Hides API keys                    ‚îÇ  ‚Ä¢ LLM Processing\n",
    "        ‚îÇ  ‚Ä¢ Manages UI state                ‚îÇ  ‚Ä¢ Rate limiting                     ‚îÇ  ‚Ä¢ Text-to-Speech\n",
    "        ‚îÇ                                    ‚îÇ  ‚Ä¢ Session management                ‚îÇ\n",
    "```\n",
    "\n",
    "### Why a Backend Proxy?\n",
    "\n",
    "1. **Security**: API keys never leave the server\n",
    "2. **Rate Limiting**: Control usage per user\n",
    "3. **Logging**: Monitor and debug conversations\n",
    "4. **Flexibility**: Add custom logic, filters, or transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf528c",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. WebSocket Fundamentals\n",
    "\n",
    "### What is a WebSocket?\n",
    "\n",
    "WebSocket is a **bidirectional, full-duplex communication protocol** over a single TCP connection. Unlike HTTP (request-response), WebSockets allow both client and server to send messages at any time.\n",
    "\n",
    "### HTTP vs WebSocket\n",
    "\n",
    "| Aspect | HTTP | WebSocket |\n",
    "|--------|------|----------|\n",
    "| Communication | Request-Response | Bidirectional |\n",
    "| Connection | New connection per request | Persistent connection |\n",
    "| Overhead | Headers on every request | Minimal framing |\n",
    "| Use Case | REST APIs, web pages | Real-time apps, streaming |\n",
    "| Latency | Higher | Lower |\n",
    "\n",
    "### Why WebSocket for Voice Chat?\n",
    "\n",
    "Voice chat requires **real-time, continuous data streaming** in both directions:\n",
    "- üé§ User's voice ‚Üí Server ‚Üí Azure (continuous audio stream)\n",
    "- üîä Azure's response ‚Üí Server ‚Üí User (continuous audio stream)\n",
    "\n",
    "HTTP would require polling or multiple requests, adding unacceptable latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b8c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WebSocket Connection Lifecycle\n",
    "# This is conceptual code - won't run without a WebSocket server\n",
    "\n",
    "import asyncio\n",
    "\n",
    "# Simulating WebSocket connection lifecycle\n",
    "class WebSocketLifecycle:\n",
    "    \"\"\"\n",
    "    Demonstrates the WebSocket connection lifecycle.\n",
    "    \n",
    "    1. CONNECTING: Initial handshake\n",
    "    2. OPEN: Connection established, can send/receive\n",
    "    3. CLOSING: Graceful shutdown initiated\n",
    "    4. CLOSED: Connection terminated\n",
    "    \"\"\"\n",
    "    \n",
    "    states = ['CONNECTING', 'OPEN', 'CLOSING', 'CLOSED']\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.state = 'CONNECTING'\n",
    "        \n",
    "    def transition(self, new_state):\n",
    "        print(f\"State: {self.state} ‚Üí {new_state}\")\n",
    "        self.state = new_state\n",
    "\n",
    "# Demonstrate state transitions\n",
    "ws = WebSocketLifecycle()\n",
    "print(\"WebSocket Connection Lifecycle:\")\n",
    "print(\"=\"*40)\n",
    "ws.transition('OPEN')      # After successful handshake\n",
    "ws.transition('CLOSING')   # Close initiated\n",
    "ws.transition('CLOSED')    # Connection terminated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0253be9",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Azure OpenAI Realtime API\n",
    "\n",
    "### What is the Realtime API?\n",
    "\n",
    "Azure OpenAI's **Realtime API** provides:\n",
    "- üé§ **Speech-to-Text**: Transcribes audio in real-time\n",
    "- üß† **LLM Processing**: Generates intelligent responses\n",
    "- üîä **Text-to-Speech**: Converts response to natural speech\n",
    "\n",
    "All in a **single WebSocket connection** with sub-second latency!\n",
    "\n",
    "### API Endpoint Structure\n",
    "\n",
    "```\n",
    "wss://{endpoint}/openai/realtime\n",
    "    ?api-version={version}\n",
    "    &deployment={deployment-name}\n",
    "    &api-key={your-api-key}\n",
    "```\n",
    "\n",
    "### Supported Models\n",
    "\n",
    "- `gpt-4o-realtime-preview` - Best quality, lower latency\n",
    "- Models are deployed to your Azure OpenAI resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa19cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Azure Realtime API URL\n",
    "# This shows how to construct the WebSocket URL for Azure OpenAI\n",
    "\n",
    "def build_azure_realtime_url(\n",
    "    endpoint: str,\n",
    "    deployment: str,\n",
    "    api_key: str,\n",
    "    api_version: str = \"2024-10-01-preview\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build the WebSocket URL for Azure OpenAI Realtime API.\n",
    "    \n",
    "    Args:\n",
    "        endpoint: Your Azure OpenAI endpoint (https://...)\n",
    "        deployment: Name of your gpt-4o-realtime deployment\n",
    "        api_key: Your Azure OpenAI API key\n",
    "        api_version: API version to use\n",
    "    \n",
    "    Returns:\n",
    "        WebSocket URL for connection\n",
    "    \"\"\"\n",
    "    # Convert HTTPS to WSS (secure WebSocket)\n",
    "    ws_endpoint = endpoint.replace('https://', 'wss://').rstrip('/')\n",
    "    \n",
    "    url = (\n",
    "        f\"{ws_endpoint}/openai/realtime\"\n",
    "        f\"?api-version={api_version}\"\n",
    "        f\"&deployment={deployment}\"\n",
    "        f\"&api-key={api_key}\"\n",
    "    )\n",
    "    return url\n",
    "\n",
    "# Example (with fake credentials)\n",
    "example_url = build_azure_realtime_url(\n",
    "    endpoint=\"https://my-openai.openai.azure.com\",\n",
    "    deployment=\"gpt-4o-realtime\",\n",
    "    api_key=\"abc123...\"\n",
    ")\n",
    "\n",
    "print(\"Azure Realtime API URL Structure:\")\n",
    "print(\"=\"*50)\n",
    "# Show URL without exposing the key\n",
    "safe_url = example_url.split('&api-key=')[0] + '&api-key=***'\n",
    "print(safe_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578aa0dd",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Audio Encoding & Processing\n",
    "\n",
    "### Audio Format Requirements\n",
    "\n",
    "Azure OpenAI Realtime API expects audio in specific formats:\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| Format | PCM (Pulse Code Modulation) |\n",
    "| Sample Rate | 24000 Hz (24 kHz) |\n",
    "| Bit Depth | 16-bit |\n",
    "| Channels | Mono (1 channel) |\n",
    "| Encoding | Base64 (for JSON messages) |\n",
    "\n",
    "### Audio Pipeline\n",
    "\n",
    "```\n",
    "Browser Microphone          Server              Azure\n",
    "      ‚îÇ                       ‚îÇ                   ‚îÇ\n",
    "      ‚îÇ  AudioWorklet         ‚îÇ                   ‚îÇ\n",
    "      ‚îÇ  captures PCM         ‚îÇ                   ‚îÇ\n",
    "      ‚ñº                       ‚îÇ                   ‚îÇ\n",
    "  Float32 samples             ‚îÇ                   ‚îÇ\n",
    "      ‚îÇ                       ‚îÇ                   ‚îÇ\n",
    "      ‚îÇ  Downsample to        ‚îÇ                   ‚îÇ\n",
    "      ‚îÇ  24kHz if needed      ‚îÇ                   ‚îÇ\n",
    "      ‚ñº                       ‚îÇ                   ‚îÇ\n",
    "  Int16 PCM                   ‚îÇ                   ‚îÇ\n",
    "      ‚îÇ                       ‚îÇ                   ‚îÇ\n",
    "      ‚îÇ  Base64 encode        ‚îÇ                   ‚îÇ\n",
    "      ‚ñº                       ‚îÇ                   ‚îÇ\n",
    "  JSON message ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫\n",
    "                              ‚îÇ                   ‚îÇ\n",
    "                              ‚îÇ                   ‚îÇ Process\n",
    "                              ‚îÇ                   ‚ñº\n",
    "  ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "      ‚îÇ                       ‚îÇ  Response audio\n",
    "      ‚îÇ  Decode & play        ‚îÇ\n",
    "      ‚ñº                       ‚îÇ\n",
    "  Speaker output              ‚îÇ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c22116",
   "metadata": {},
   "source": [
    "---\n",
    "## 4a. Microsoft Agent Framework (Text Mode)\n",
    "\n",
    "### What is Microsoft Agent Framework?\n",
    "\n",
    "The **Microsoft Agent Framework** provides a unified way to build AI agents across Python and .NET:\n",
    "\n",
    "- ü§ñ **ChatAgent**: High-level abstraction for chat-based AI interactions\n",
    "- üßµ **AgentSession**: Manages conversation history across multiple turns\n",
    "- üîß **Tool Support**: Native functions, OpenAPI, and MCP (Model Context Protocol)\n",
    "- ‚òÅÔ∏è **Multi-Provider**: Azure OpenAI, OpenAI, Microsoft Foundry, and more\n",
    "\n",
    "### Why Use Agent Framework?\n",
    "\n",
    "| Feature | Direct API Calls | Agent Framework |\n",
    "|---------|-----------------|-----------------|\n",
    "| Conversation Memory | Manual management | Built-in sessions |\n",
    "| Tool/Function Calling | Complex setup | Declarative |\n",
    "| Multi-turn Context | Implement yourself | Automatic |\n",
    "| Streaming Responses | Manual parsing | Built-in support |\n",
    "| Cross-platform | Separate implementations | Same patterns (Python & .NET) |\n",
    "\n",
    "### Package Installation (Python)\n",
    "\n",
    "```bash\n",
    "# The --pre flag is required while Agent Framework is in preview\n",
    "pip install agent-framework-core agent-framework-azure-ai --pre\n",
    "```\n",
    "\n",
    "### Key Classes\n",
    "\n",
    "| Class | Purpose |\n",
    "|-------|---------|\n",
    "| `AzureOpenAIChatClient` | Connect to Azure OpenAI with explicit settings |\n",
    "| `create_agent()` | Create an agent from the chat client |\n",
    "| `agent.create_session()` | Create conversation session for multi-turn chat |\n",
    "| `agent.run()` | Run agent and get response |\n",
    "| `agent.run_stream()` | Run agent with streaming response |\n",
    "\n",
    "### Comparison with .NET\n",
    "\n",
    "| Python | .NET |\n",
    "|--------|------|\n",
    "| `AzureOpenAIChatClient` | `AzureOpenAIClient` |\n",
    "| `client.create_agent()` | `chatClient.CreateAIAgent()` |\n",
    "| `agent.run()` | `agent.RunAsync()` |\n",
    "| `agent.run_stream()` | `agent.RunStreamingAsync()` |\n",
    "| `agent.create_session()` | `agent.CreateSessionAsync()` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microsoft Agent Framework - AzureOpenAIChatClient Pattern (as used in server.py)\n",
    "# This demonstrates the pattern used in the Voice Chat backend for text mode\n",
    "\n",
    "AGENT_SERVICE_CODE = '''\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "# Global agent instance (singleton pattern)\n",
    "_chat_agent = None\n",
    "_chat_client = None\n",
    "\n",
    "async def get_chat_agent():\n",
    "    \"\"\"\n",
    "    Get or create the ChatAgent instance (singleton pattern like .NET).\n",
    "    Uses Microsoft Agent Framework with Azure OpenAI.\n",
    "    \n",
    "    Pattern follows:\n",
    "    https://github.com/microsoft/agent-framework/tree/main/python/samples/getting_started/agents/azure_openai\n",
    "    \"\"\"\n",
    "    global _chat_agent, _chat_client\n",
    "    \n",
    "    if _chat_agent is not None:\n",
    "        return _chat_agent\n",
    "    \n",
    "    # Create the Azure OpenAI Chat Client with explicit settings\n",
    "    # This mirrors the .NET pattern: AzureOpenAIClient -> GetChatClient -> CreateAIAgent\n",
    "    _chat_client = AzureOpenAIChatClient(\n",
    "        endpoint=AZURE_ENDPOINT,\n",
    "        deployment_name=AZURE_CHAT_DEPLOYMENT,\n",
    "        api_key=AZURE_API_KEY,\n",
    "    )\n",
    "    \n",
    "    # Create agent from the chat client (like .NET's CreateAIAgent)\n",
    "    _chat_agent = _chat_client.create_agent(\n",
    "        instructions=\"You are a helpful assistant. Respond naturally and concisely.\",\n",
    "    )\n",
    "    \n",
    "    return _chat_agent\n",
    "\n",
    "\n",
    "async def handle_text_mode(websocket, session_id: str):\n",
    "    \"\"\"Handle Text Mode connection using Microsoft Agent Framework.\"\"\"\n",
    "    \n",
    "    agent = await get_chat_agent()\n",
    "    \n",
    "    # Create a new session for this conversation session\n",
    "    # (like .NET's agent.CreateSessionAsync())\n",
    "    session = await agent.create_session()\n",
    "    \n",
    "    async for message in websocket:\n",
    "        data = json.loads(message)\n",
    "        user_message = data.get('content', '')\n",
    "        \n",
    "        # Run the agent with the user's message (mirrors .NET's agent.RunAsync)\n",
    "        result = await agent.run(user_message, session=session)\n",
    "        \n",
    "        # AgentRunResponse can be converted to string for the text content\n",
    "        response_text = str(result) if result else \"No response generated.\"\n",
    "        \n",
    "        await websocket.send(json.dumps({\n",
    "            'type': 'text_response',\n",
    "            'content': response_text\n",
    "        }))\n",
    "'''\n",
    "\n",
    "print(\"AzureOpenAIChatClient Pattern - Text Mode Handler:\")\n",
    "print(\"=\"*60)\n",
    "print(AGENT_SERVICE_CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40d1043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent session for Multi-turn Conversations\n",
    "# AgentSession maintains conversation context across multiple user interactions\n",
    "\n",
    "THREAD_PATTERN_CODE = '''\n",
    "# Multi-turn conversation using AgentSession\n",
    "# Pattern from: https://github.com/microsoft/agent-framework/tree/main/python/samples/getting_started/agents/azure_openai/azure_chat_client_with_session.py\n",
    "\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "async def demo_multi_turn_conversation():\n",
    "    \"\"\"Demonstrate conversation memory with AgentSession.\"\"\"\n",
    "    \n",
    "    # Create client and agent\n",
    "    client = AzureOpenAIChatClient(\n",
    "        endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        deployment_name=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    "        api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    )\n",
    "    \n",
    "    agent = client.create_agent(\n",
    "        instructions=\"You are a helpful assistant.\",\n",
    "    )\n",
    "    \n",
    "    # Create a new session for conversation history\n",
    "    session = await agent.create_session()\n",
    "    \n",
    "    # First turn\n",
    "    result1 = await agent.run(\"My name is Alice\", session=session)\n",
    "    print(f\"Agent: {result1}\")\n",
    "    # Agent: \"Nice to meet you, Alice!\"\n",
    "    \n",
    "    # Second turn - agent remembers the context via thread\n",
    "    result2 = await agent.run(\"What is my name?\", session=session)\n",
    "    print(f\"Agent: {result2}\")\n",
    "    # Agent: \"Your name is Alice!\"\n",
    "    \n",
    "    # Without thread, each call would be independent\n",
    "    # The thread automatically manages the conversation history\n",
    "\n",
    "\n",
    "# Adding tools/functions to the agent\n",
    "from typing import Annotated\n",
    "from random import randint\n",
    "from pydantic import Field\n",
    "\n",
    "def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    return f\"The weather in {location} is {conditions[randint(0, 3)]} with a high of {randint(10, 30)}¬∞C.\"\n",
    "\n",
    "# Agent with tools\n",
    "agent_with_tools = client.create_agent(\n",
    "    instructions=\"You are a helpful weather assistant.\",\n",
    "    tools=[get_weather],  # Add callable functions as tools\n",
    ")\n",
    "\n",
    "# The agent can now call get_weather when user asks about weather\n",
    "result = await agent_with_tools.run(\"What's the weather like in Seattle?\")\n",
    "# Agent will call get_weather(\"Seattle\") and incorporate the result\n",
    "'''\n",
    "\n",
    "print(\"AgentSession - Multi-turn Conversations & Tools:\")\n",
    "print(\"=\"*60)\n",
    "print(THREAD_PATTERN_CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7125c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import struct\n",
    "import math\n",
    "\n",
    "# Audio processing concepts\n",
    "\n",
    "def float32_to_int16(samples: list) -> bytes:\n",
    "    \"\"\"\n",
    "    Convert float32 audio samples (-1.0 to 1.0) to int16 PCM.\n",
    "    This is what happens in the browser's AudioWorklet.\n",
    "    \n",
    "    Args:\n",
    "        samples: List of float32 samples in range [-1.0, 1.0]\n",
    "    \n",
    "    Returns:\n",
    "        Bytes containing int16 PCM data\n",
    "    \"\"\"\n",
    "    int16_samples = []\n",
    "    for sample in samples:\n",
    "        # Clamp to valid range\n",
    "        clamped = max(-1.0, min(1.0, sample))\n",
    "        # Scale to int16 range (-32768 to 32767)\n",
    "        int16_value = int(clamped * 32767)\n",
    "        int16_samples.append(int16_value)\n",
    "    \n",
    "    # Pack as little-endian int16\n",
    "    return struct.pack(f'<{len(int16_samples)}h', *int16_samples)\n",
    "\n",
    "\n",
    "def pcm_to_base64(pcm_bytes: bytes) -> str:\n",
    "    \"\"\"\n",
    "    Convert PCM bytes to base64 string for JSON transport.\n",
    "    \n",
    "    Args:\n",
    "        pcm_bytes: Raw PCM audio bytes\n",
    "    \n",
    "    Returns:\n",
    "        Base64 encoded string\n",
    "    \"\"\"\n",
    "    return base64.b64encode(pcm_bytes).decode('utf-8')\n",
    "\n",
    "\n",
    "# Demonstrate with a simple sine wave (440 Hz = A4 note)\n",
    "sample_rate = 24000  # 24 kHz as required by Azure\n",
    "frequency = 440  # Hz\n",
    "duration = 0.01  # 10 milliseconds\n",
    "\n",
    "# Generate sine wave samples\n",
    "num_samples = int(sample_rate * duration)\n",
    "sine_wave = [math.sin(2 * math.pi * frequency * i / sample_rate) for i in range(num_samples)]\n",
    "\n",
    "# Convert to int16 PCM\n",
    "pcm_data = float32_to_int16(sine_wave)\n",
    "\n",
    "# Convert to base64 for JSON transport\n",
    "base64_audio = pcm_to_base64(pcm_data)\n",
    "\n",
    "print(\"Audio Encoding Example (440 Hz sine wave, 10ms):\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Sample rate: {sample_rate} Hz\")\n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"PCM bytes: {len(pcm_data)} bytes\")\n",
    "print(f\"Base64 length: {len(base64_audio)} characters\")\n",
    "print(f\"\\nBase64 preview: {base64_audio[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb10228d",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Session Management\n",
    "\n",
    "### Why Session Management?\n",
    "\n",
    "Real-time voice applications need to:\n",
    "- Track active connections\n",
    "- Associate users with their sessions\n",
    "- Clean up resources when connections close\n",
    "- Implement rate limiting per user\n",
    "\n",
    "### Session Structure\n",
    "\n",
    "```python\n",
    "session = {\n",
    "    'session_id': 'uuid-string',\n",
    "    'user_id': 'user-identifier',\n",
    "    'mode': 'voice' | 'text',\n",
    "    'created_at': datetime,\n",
    "    'azure_ws': WebSocket,  # Connection to Azure\n",
    "    'client_ws': WebSocket, # Connection to browser\n",
    "    'message_count': 0\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b70a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from datetime import datetime\n",
    "from typing import Dict, Set, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "class SessionManager:\n",
    "    \"\"\"\n",
    "    Manages voice chat sessions with rate limiting.\n",
    "    \n",
    "    Features:\n",
    "    - Create/cleanup sessions\n",
    "    - Track sessions per user\n",
    "    - Enforce connection limits\n",
    "    - Rate limiting\n",
    "    \"\"\"\n",
    "    \n",
    "    MAX_CONNECTIONS_PER_USER = 3\n",
    "    MAX_REQUESTS_PER_MINUTE = 60\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sessions: Dict[str, dict] = {}\n",
    "        self.user_connections: Dict[str, Set[str]] = defaultdict(set)\n",
    "        self.user_requests: Dict[str, list] = defaultdict(list)\n",
    "    \n",
    "    def create_session(self, user_id: str, mode: str) -> str:\n",
    "        \"\"\"Create a new session for a user.\"\"\"\n",
    "        session_id = str(uuid.uuid4())\n",
    "        self.sessions[session_id] = {\n",
    "            'user_id': user_id,\n",
    "            'mode': mode,\n",
    "            'created_at': datetime.now(),\n",
    "            'message_count': 0\n",
    "        }\n",
    "        self.user_connections[user_id].add(session_id)\n",
    "        return session_id\n",
    "    \n",
    "    def cleanup_session(self, session_id: str):\n",
    "        \"\"\"Clean up session resources.\"\"\"\n",
    "        if session_id in self.sessions:\n",
    "            user_id = self.sessions[session_id]['user_id']\n",
    "            self.user_connections[user_id].discard(session_id)\n",
    "            del self.sessions[session_id]\n",
    "    \n",
    "    def check_rate_limit(self, user_id: str) -> tuple:\n",
    "        \"\"\"Check if user is within rate limits.\"\"\"\n",
    "        # Connection limit\n",
    "        if len(self.user_connections[user_id]) >= self.MAX_CONNECTIONS_PER_USER:\n",
    "            return False, \"Max connections exceeded\"\n",
    "        \n",
    "        # Request rate limit\n",
    "        now = datetime.now()\n",
    "        recent = [ts for ts in self.user_requests[user_id] \n",
    "                  if (now - ts).total_seconds() < 60]\n",
    "        self.user_requests[user_id] = recent\n",
    "        \n",
    "        if len(recent) >= self.MAX_REQUESTS_PER_MINUTE:\n",
    "            return False, \"Rate limit exceeded\"\n",
    "        \n",
    "        self.user_requests[user_id].append(now)\n",
    "        return True, \"OK\"\n",
    "    \n",
    "    def get_stats(self) -> dict:\n",
    "        \"\"\"Get session statistics.\"\"\"\n",
    "        return {\n",
    "            'total_sessions': len(self.sessions),\n",
    "            'unique_users': len(self.user_connections),\n",
    "            'sessions_by_mode': {\n",
    "                mode: sum(1 for s in self.sessions.values() if s['mode'] == mode)\n",
    "                for mode in ['voice', 'text']\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Demo\n",
    "manager = SessionManager()\n",
    "\n",
    "print(\"Session Management Demo:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create sessions\n",
    "session1 = manager.create_session('user-alice', 'voice')\n",
    "session2 = manager.create_session('user-alice', 'text')\n",
    "session3 = manager.create_session('user-bob', 'voice')\n",
    "\n",
    "print(f\"Created session for Alice (voice): {session1[:8]}...\")\n",
    "print(f\"Created session for Alice (text): {session2[:8]}...\")\n",
    "print(f\"Created session for Bob (voice): {session3[:8]}...\")\n",
    "\n",
    "print(f\"\\nStatistics: {manager.get_stats()}\")\n",
    "\n",
    "# Rate limit check\n",
    "allowed, msg = manager.check_rate_limit('user-alice')\n",
    "print(f\"\\nRate limit check for Alice: {allowed} - {msg}\")\n",
    "\n",
    "# Cleanup\n",
    "manager.cleanup_session(session1)\n",
    "print(f\"\\nAfter cleanup: {manager.get_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d10b4",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Message Protocol\n",
    "\n",
    "### Azure Realtime API Message Types\n",
    "\n",
    "The Realtime API uses JSON messages for control and base64-encoded audio.\n",
    "\n",
    "#### Client ‚Üí Azure Messages\n",
    "\n",
    "| Message Type | Purpose |\n",
    "|--------------|--------|\n",
    "| `session.update` | Configure session (voice, instructions) |\n",
    "| `input_audio_buffer.append` | Send audio chunks |\n",
    "| `input_audio_buffer.commit` | Commit audio for processing |\n",
    "| `response.create` | Request a response |\n",
    "\n",
    "#### Azure ‚Üí Client Messages\n",
    "\n",
    "| Message Type | Purpose |\n",
    "|--------------|--------|\n",
    "| `session.created` | Session initialized |\n",
    "| `session.updated` | Session config confirmed |\n",
    "| `input_audio_buffer.speech_started` | Voice activity detected |\n",
    "| `input_audio_buffer.speech_stopped` | Voice activity ended |\n",
    "| `response.audio.delta` | Audio chunk of response |\n",
    "| `response.audio_transcript.delta` | Transcript of response |\n",
    "| `response.done` | Response complete |\n",
    "| `error` | Error occurred |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3593e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Message Protocol Examples\n",
    "\n",
    "# 1. Session Configuration\n",
    "session_update = {\n",
    "    \"type\": \"session.update\",\n",
    "    \"session\": {\n",
    "        \"modalities\": [\"text\", \"audio\"],\n",
    "        \"instructions\": \"You are a helpful assistant. Respond naturally and concisely.\",\n",
    "        \"voice\": \"alloy\",  # Options: alloy, echo, shimmer\n",
    "        \"input_audio_format\": \"pcm16\",\n",
    "        \"output_audio_format\": \"pcm16\",\n",
    "        \"input_audio_transcription\": {\n",
    "            \"model\": \"whisper-1\"\n",
    "        },\n",
    "        \"turn_detection\": {\n",
    "            \"type\": \"server_vad\",  # Server-side voice activity detection\n",
    "            \"threshold\": 0.5,\n",
    "            \"prefix_padding_ms\": 300,\n",
    "            \"silence_duration_ms\": 200\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2. Send Audio Buffer\n",
    "audio_append = {\n",
    "    \"type\": \"input_audio_buffer.append\",\n",
    "    \"audio\": \"BASE64_ENCODED_PCM16_AUDIO_DATA\"\n",
    "}\n",
    "\n",
    "# 3. Response from Azure (example)\n",
    "azure_response = {\n",
    "    \"type\": \"response.audio.delta\",\n",
    "    \"response_id\": \"resp_ABC123\",\n",
    "    \"item_id\": \"item_XYZ\",\n",
    "    \"output_index\": 0,\n",
    "    \"content_index\": 0,\n",
    "    \"delta\": \"BASE64_ENCODED_AUDIO_RESPONSE\"\n",
    "}\n",
    "\n",
    "# 4. Error Message\n",
    "error_message = {\n",
    "    \"type\": \"error\",\n",
    "    \"error\": {\n",
    "        \"type\": \"invalid_request_error\",\n",
    "        \"code\": \"invalid_audio_format\",\n",
    "        \"message\": \"Audio must be pcm16 format\",\n",
    "        \"param\": \"audio\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Message Protocol Examples:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n1. Session Update (Client ‚Üí Azure):\")\n",
    "print(json.dumps(session_update, indent=2)[:500] + \"...\")\n",
    "\n",
    "print(\"\\n2. Audio Append (Client ‚Üí Azure):\")\n",
    "print(json.dumps(audio_append, indent=2))\n",
    "\n",
    "print(\"\\n3. Audio Response (Azure ‚Üí Client):\")\n",
    "print(json.dumps(azure_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0878dd86",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Security Best Practices\n",
    "\n",
    "### üîê Key Security Principles\n",
    "\n",
    "1. **Never expose API keys to the client**\n",
    "   - All Azure calls go through the backend proxy\n",
    "   - Keys stored in environment variables on server\n",
    "\n",
    "2. **Implement authentication**\n",
    "   - Validate user tokens before allowing WebSocket connections\n",
    "   - Use JWT or OAuth2 in production\n",
    "\n",
    "3. **Rate limiting**\n",
    "   - Limit connections per user\n",
    "   - Limit requests per time window\n",
    "   - Prevent abuse and control costs\n",
    "\n",
    "4. **Input validation**\n",
    "   - Validate message formats\n",
    "   - Sanitize any user content\n",
    "   - Limit message sizes\n",
    "\n",
    "5. **Use secure connections**\n",
    "   - WSS (WebSocket Secure) only\n",
    "   - HTTPS for any HTTP endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Security Implementation Patterns\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional\n",
    "import hashlib\n",
    "import hmac\n",
    "import secrets\n",
    "\n",
    "class SecurityManager:\n",
    "    \"\"\"\n",
    "    Security utilities for voice chat application.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, secret_key: str):\n",
    "        self.secret_key = secret_key.encode()\n",
    "        self.token_expiry = timedelta(hours=1)\n",
    "    \n",
    "    def generate_session_token(self, user_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate a secure session token.\n",
    "        In production, use JWT with proper claims.\n",
    "        \"\"\"\n",
    "        timestamp = datetime.utcnow().isoformat()\n",
    "        data = f\"{user_id}:{timestamp}\"\n",
    "        signature = hmac.new(\n",
    "            self.secret_key, \n",
    "            data.encode(), \n",
    "            hashlib.sha256\n",
    "        ).hexdigest()\n",
    "        return f\"{data}:{signature}\"\n",
    "    \n",
    "    def validate_token(self, token: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Validate a session token and return user_id if valid.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            parts = token.rsplit(':', 1)\n",
    "            if len(parts) != 2:\n",
    "                return None\n",
    "            \n",
    "            data, signature = parts\n",
    "            expected_sig = hmac.new(\n",
    "                self.secret_key, \n",
    "                data.encode(), \n",
    "                hashlib.sha256\n",
    "            ).hexdigest()\n",
    "            \n",
    "            if not hmac.compare_digest(signature, expected_sig):\n",
    "                return None\n",
    "            \n",
    "            user_id, timestamp = data.rsplit(':', 1)\n",
    "            # Check expiry (simplified)\n",
    "            return user_id\n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_audio_message(message: dict) -> tuple:\n",
    "        \"\"\"\n",
    "        Validate an audio message structure.\n",
    "        \"\"\"\n",
    "        required_fields = ['type']\n",
    "        \n",
    "        for field in required_fields:\n",
    "            if field not in message:\n",
    "                return False, f\"Missing required field: {field}\"\n",
    "        \n",
    "        # Validate audio size if present\n",
    "        if 'audio' in message:\n",
    "            max_audio_size = 1024 * 1024  # 1MB\n",
    "            if len(message['audio']) > max_audio_size:\n",
    "                return False, \"Audio data exceeds maximum size\"\n",
    "        \n",
    "        return True, \"Valid\"\n",
    "\n",
    "# Demo\n",
    "security = SecurityManager(\"my-super-secret-key-change-in-production\")\n",
    "\n",
    "print(\"Security Demo:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Generate token\n",
    "token = security.generate_session_token(\"user-alice\")\n",
    "print(f\"Generated token: {token[:50]}...\")\n",
    "\n",
    "# Validate token\n",
    "user_id = security.validate_token(token)\n",
    "print(f\"Validated user: {user_id}\")\n",
    "\n",
    "# Validate message\n",
    "test_msg = {\"type\": \"input_audio_buffer.append\", \"audio\": \"SGVsbG8=\"}\n",
    "valid, msg = SecurityManager.validate_audio_message(test_msg)\n",
    "print(f\"Message validation: {valid} - {msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e00bca",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Code Examples\n",
    "\n",
    "### Complete WebSocket Proxy Pattern\n",
    "\n",
    "The core pattern for proxying WebSocket connections between a client and Azure is **bidirectional forwarding**:\n",
    "\n",
    "```python\n",
    "async def handle_voice_session(client_ws, azure_url):\n",
    "    async with websockets.connect(azure_url) as azure_ws:\n",
    "        # Run both directions concurrently\n",
    "        await asyncio.gather(\n",
    "            proxy_client_to_azure(client_ws, azure_ws),\n",
    "            proxy_azure_to_client(azure_ws, client_ws)\n",
    "        )\n",
    "```\n",
    "\n",
    "This ensures:\n",
    "- Audio from client reaches Azure in real-time\n",
    "- Azure's responses reach client with minimal latency\n",
    "- Both connections are properly managed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6074912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete WebSocket Server Example (Conceptual)\n",
    "# This shows the full structure but won't run without websockets library\n",
    "\n",
    "WEBSOCKET_SERVER_CODE = '''\n",
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Configuration from environment\n",
    "AZURE_ENDPOINT = os.getenv('AZURE_ENDPOINT')\n",
    "AZURE_API_KEY = os.getenv('AZURE_API_KEY')\n",
    "AZURE_DEPLOYMENT = os.getenv('AZURE_REALTIME_DEPLOYMENT')\n",
    "API_VERSION = '2024-10-01-preview'\n",
    "\n",
    "def build_azure_url():\n",
    "    \"\"\"Build Azure Realtime API WebSocket URL.\"\"\"\n",
    "    ws_endpoint = AZURE_ENDPOINT.replace('https://', 'wss://').rstrip('/')\n",
    "    return (\n",
    "        f\"{ws_endpoint}/openai/realtime\"\n",
    "        f\"?api-version={API_VERSION}\"\n",
    "        f\"&deployment={AZURE_DEPLOYMENT}\"\n",
    "        f\"&api-key={AZURE_API_KEY}\"\n",
    "    )\n",
    "\n",
    "async def proxy_client_to_azure(client_ws, azure_ws):\n",
    "    \"\"\"Forward messages from browser to Azure.\"\"\"\n",
    "    async for message in client_ws:\n",
    "        await azure_ws.send(message)\n",
    "\n",
    "async def proxy_azure_to_client(azure_ws, client_ws):\n",
    "    \"\"\"Forward messages from Azure to browser.\"\"\"\n",
    "    async for message in azure_ws:\n",
    "        await client_ws.send(message)\n",
    "\n",
    "async def handle_connection(client_ws):\n",
    "    \"\"\"Handle a new WebSocket connection.\"\"\"\n",
    "    print(f\"New client connected\")\n",
    "    \n",
    "    azure_url = build_azure_url()\n",
    "    \n",
    "    async with websockets.connect(\n",
    "        azure_url,\n",
    "        max_size=10 * 1024 * 1024,  # 10MB\n",
    "        ping_interval=20\n",
    "    ) as azure_ws:\n",
    "        print(f\"Connected to Azure Realtime API\")\n",
    "        \n",
    "        # Bidirectional proxy\n",
    "        await asyncio.gather(\n",
    "            proxy_client_to_azure(client_ws, azure_ws),\n",
    "            proxy_azure_to_client(azure_ws, client_ws),\n",
    "            return_exceptions=True\n",
    "        )\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Start the WebSocket server.\"\"\"\n",
    "    async with websockets.serve(\n",
    "        handle_connection,\n",
    "        \"0.0.0.0\",\n",
    "        8001,\n",
    "        max_size=10 * 1024 * 1024\n",
    "    ):\n",
    "        print(\"Voice Chat Server running on ws://0.0.0.0:8001\")\n",
    "        await asyncio.Future()  # Run forever\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "'''\n",
    "\n",
    "print(\"Complete WebSocket Server Structure:\")\n",
    "print(\"=\"*50)\n",
    "print(WEBSOCKET_SERVER_CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de9aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Mode: Using Microsoft Agent Framework\n",
    "# The voice chat app uses Agent Framework for text mode (same patterns as .NET)\n",
    "\n",
    "import json\n",
    "\n",
    "TEXT_CHAT_CODE = '''\n",
    "# Text mode with Microsoft Agent Framework\n",
    "# This replaces direct REST API calls with the unified Agent pattern\n",
    "# Pattern from: https://github.com/microsoft/agent-framework/tree/main/python/samples/getting_started/agents/azure_openai\n",
    "\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "import os\n",
    "\n",
    "async def setup_text_mode():\n",
    "    \"\"\"Initialize ChatAgent for text mode chat.\"\"\"\n",
    "    \n",
    "    # Create Azure OpenAI chat client with explicit settings\n",
    "    # (like .NET's AzureOpenAIClient.GetChatClient)\n",
    "    client = AzureOpenAIChatClient(\n",
    "        endpoint=os.getenv('AZURE_ENDPOINT'),\n",
    "        deployment_name=os.getenv('AZURE_CHAT_DEPLOYMENT', 'gpt-4o'),\n",
    "        api_key=os.getenv('AZURE_API_KEY'),\n",
    "    )\n",
    "    \n",
    "    # Create the agent (like .NET's CreateAIAgent)\n",
    "    agent = client.create_agent(\n",
    "        instructions=\"You are a helpful assistant.\",\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "\n",
    "async def handle_text_session(websocket, agent):\n",
    "    \"\"\"Handle a text chat session with conversation memory.\"\"\"\n",
    "    \n",
    "    # Create session for this session (maintains context across turns)\n",
    "    session = await agent.create_session()\n",
    "    \n",
    "    async for message in websocket:\n",
    "        data = json.loads(message)\n",
    "        user_message = data.get('content', '')\n",
    "        \n",
    "        # Run agent and get response (with conversation history via thread)\n",
    "        result = await agent.run(user_message, session=session)\n",
    "        \n",
    "        await websocket.send(json.dumps({\n",
    "            'type': 'text_response',\n",
    "            'content': str(result)\n",
    "        }))\n",
    "\n",
    "\n",
    "# For streaming responses (better UX for long responses):\n",
    "async def handle_text_session_streaming(websocket, agent):\n",
    "    \"\"\"Handle text chat with streaming responses.\"\"\"\n",
    "    \n",
    "    session = await agent.create_session()\n",
    "    \n",
    "    async for message in websocket:\n",
    "        data = json.loads(message)\n",
    "        user_message = data.get('content', '')\n",
    "        \n",
    "        # Stream response chunks\n",
    "        response_text = \"\"\n",
    "        async for chunk in agent.run_stream(user_message, session=session):\n",
    "            if chunk.text:\n",
    "                response_text += chunk.text\n",
    "                # Optionally send partial updates to client\n",
    "        \n",
    "        await websocket.send(json.dumps({\n",
    "            'type': 'text_response',\n",
    "            'content': response_text\n",
    "        }))\n",
    "\n",
    "\n",
    "# Benefits over direct API calls:\n",
    "# 1. Automatic conversation history management via AgentSession\n",
    "# 2. Built-in streaming support with run_stream()\n",
    "# 3. Easy tool/function integration\n",
    "# 4. Same patterns as .NET implementation\n",
    "# 5. Environment variable auto-loading from AZURE_OPENAI_* vars\n",
    "'''\n",
    "\n",
    "print(\"Text Chat with Microsoft Agent Framework:\")\n",
    "print(\"=\"*50)\n",
    "print(TEXT_CHAT_CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce3258",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Summary\n",
    "\n",
    "### Key Concepts Learned\n",
    "\n",
    "1. **WebSocket Architecture**: Bidirectional, persistent connections for real-time communication\n",
    "\n",
    "2. **Proxy Pattern**: Backend server acts as intermediary between browser and Azure for security\n",
    "\n",
    "3. **Audio Processing**: PCM16 at 24kHz, base64 encoded for JSON transport\n",
    "\n",
    "4. **Session Management**: Track users, connections, and implement rate limiting\n",
    "\n",
    "5. **Message Protocol**: JSON-based control messages with specific types for each action\n",
    "\n",
    "6. **Security**: Never expose API keys, validate inputs, use secure connections\n",
    "\n",
    "7. **Microsoft Agent Framework**: `AzureOpenAIChatClient.create_agent()` for text mode with conversation memory\n",
    "\n",
    "### Agent Framework Packages\n",
    "\n",
    "```bash\n",
    "# The --pre flag is required while Agent Framework is in preview\n",
    "pip install agent-framework-core agent-framework-azure-ai --pre\n",
    "```\n",
    "\n",
    "### Key Imports\n",
    "\n",
    "```python\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "# Create client and agent\n",
    "client = AzureOpenAIChatClient(\n",
    "    endpoint=\"https://your-resource.openai.azure.com\",\n",
    "    deployment_name=\"gpt-4o\",\n",
    "    api_key=\"your-api-key\",\n",
    ")\n",
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    ")\n",
    "\n",
    "# Use session for multi-turn conversation\n",
    "session = await agent.create_session()\n",
    "result = await agent.run(\"Hello!\", session=session)\n",
    "```\n",
    "\n",
    "### Cross-Platform Consistency\n",
    "\n",
    "The same Agent Framework patterns work in both Python and .NET:\n",
    "\n",
    "| Python | .NET |\n",
    "|--------|------|\n",
    "| `AzureOpenAIChatClient` | `AzureOpenAIClient` |\n",
    "| `client.create_agent()` | `chatClient.CreateAIAgent()` |\n",
    "| `agent.run()` | `agent.RunAsync()` |\n",
    "| `agent.run_stream()` | `agent.RunStreamingAsync()` |\n",
    "| `agent.create_session()` | `agent.CreateSessionAsync()` |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Run the actual voice chat application to see these concepts in action\n",
    "- Explore the browser-side code for audio capture and playback\n",
    "- Experiment with different voice settings and system prompts\n",
    "- Try adding tools/functions to the agent for enhanced capabilities\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Azure OpenAI Realtime API Documentation](https://learn.microsoft.com/azure/ai-services/openai/realtime-audio-quickstart)\n",
    "- [Microsoft Agent Framework - Python Samples](https://github.com/microsoft/agent-framework/tree/main/python/samples/getting_started/agents/azure_openai)\n",
    "- [Microsoft Agent Framework - GitHub](https://github.com/microsoft/agent-framework)\n",
    "- [WebSocket Protocol RFC](https://datatracker.ietf.org/doc/html/rfc6455)\n",
    "- [Python websockets library](https://websockets.readthedocs.io/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
